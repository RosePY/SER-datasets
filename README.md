# Spoken Emotion Recognition Datasets

| <sub>Dataset</sub>                                                                                                                                                                                  | <sub>Year</sub> | <sub>Content</sub>                                                                                                                                    | <sub>Emotions</sub>                                                                                                                                                                                                                                                          | <sub>Format</sub>             | <sub>Size</sub>     | <sub>Language</sub>           | <sub>Paper</sub>                                                                                                                                                                                                                                                        |   Access           |      license                                                                                                                                               |
|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------|---------------------|-------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------|
| <sub>[MSP-Podcast corpus](https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Podcast.html)</sub>                                                                                            | <sub>2020</sub> | <sub>100 hours by over 100 speakers (see db link for details).</sub>                                                                                  | <sub>This corpus is annotated with emotional labels using attribute-based descriptors (activation, dominance and valence) and categorical labels (anger, happiness, sadness, disgust, surprised, fear, contempt, neutral and other). </sub>                                  | <sub> Audio </sub>            | <sub> -- </sub>     | <sub> -- </sub>               | <sub>[The MSP-Conversation Corpus](http://www.interspeech2020.org/index.php?m=content&c=index&a=show&catid=290&id=684)</sub>                                                                                                                                            | Restricted access  | Available under an Academic License & Commercial License                                                                                                   |
| <sub>[URDU-Dataset](https://github.com/siddiquelatif/urdu-dataset)</sub>                                                                                                                            | <sub>2020</sub> | <sub>400 utterances by 38 speakers (27 male and 11 female).</sub>                                                                                     | <sub>4 emotions: angry, happy, neutral, and sad.</sub>                                                                                                                                                                                                                       | <sub> Audio </sub>            | <sub>~72.1 MB</sub> | <sub>Urdu</sub>               | <sub>[Cross Lingual Speech Emotion Recognition: Urdu vs. Western Languages](https://arxiv.org/pdf/1812.10411.pdf)</sub>                                                                                                                                                 | Open access        | None specified                                                                                                                                             |
| <sub>[MELD](https://affective-meld.github.io/)</sub>                                                                                                                                                | <sub>2019</sub> | <sub>1400 dialogues and 14000 utterances from Friends TV series  by multiple speakers.</sub>                                                          | <sub>7 emotions: Anger, disgust, sadness, joy, neutral, surprise and fear.  MELD also has sentiment (positive, negative and neutral) annotation  for each utterance.</sub>                                                                                                   | <sub>Audio, Video, Text</sub> | <sub>~10.1 GB</sub> | <sub>English</sub>            | <sub>[MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations](https://arxiv.org/pdf/1810.02508.pdf)</sub>                                                                                                                                      | Open access        | [GPL-3.0 License](https://github.com/declare-lab/MELD/blob/master/LICENSE)                                                                                 |
| <sub>[ShEMO](https://github.com/mansourehk/ShEMO)</sub>                                                                                                                                             | <sub>2019</sub> | <sub> 3000 semi-natural utterances, equivalent to 3 hours and 25 minutes of speech data from online radio plays by 87 native-Persian speakers. </sub> | <sub>6 emotions: anger, fear, happiness, sadness, neutral and surprise. </sub>                                                                                                                                                                                               | <sub>Audio</sub>              | <sub>~1014 MB</sub> | <sub>Persian</sub>            | <sub>[ShEMO: a large-scale validated database for Persian speech emotion detection](https://link.springer.com/article/10.1007/s10579-018-9427-x)</sub>                                                                                                                  | Open access        | None sepcified                                                                                                                                             |
| <sub>[Emov-DB](https://mega.nz/#F!KBp32apT!gLIgyWf9iQ-yqnWFUFuUHg!mYwUnI4K)</sub>                                                                                                                   | <sub>2018</sub> | <sub>Recordings for 4 speakers- 2 males and 2 females.</sub>                                                                                          | <sub>The emotional styles are neutral, sleepiness, anger, disgust and amused.</sub>                                                                                                                                                                                          | <sub>Audio</sub>              | <sub>5.88 GB</sub>  | <sub>English</sub>            | <sub>[The emotional voices database: Towards controlling the emotion dimension in voice generation systems](https://arxiv.org/pdf/1806.09514.pdf)</sub>                                                                                                                 | Open access        | None specified                                                                                                                                             |
| <sub>[RAVDESS](https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio)</sub>                                                                                                             | <sub>2018</sub> | <sub>7356 recordings by 24 actors.</sub>                                                                                                              | <sub>7 emotions: calm, happy, sad, angry, fearful, surprise, and disgust</sub>                                                                                                                                                                                               | <sub>Audio, Video</sub>       | <sub>~24.8 GB</sub> | <sub>English</sub>            | <sub>[The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196391)</sub>                   | Open access        | [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)                                                                                      |
| <sub>[JL corpus](https://www.kaggle.com/tli725/jl-corpus)</sub>                                                                                                                                     | <sub>2018</sub> | <sub>2400 recording of 240 sentences by 4 actors (2 males and 2 females).</sub>                                                                       | <sub>5 primary emotions: angry, sad, neutral, happy, excited. 5 secondary emotions: anxious, apologetic, pensive, worried, enthusiastic.</sub>                                                                                                                               | <sub>Audio</sub>              | <sub> -- </sub>     | <sub>English</sub>            | <sub>[An Open Source Emotional Speech Corpus for Human Robot Interaction Applications](https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1349.pdf)</sub>                                                                                                        | Open access        | [CC0 1.0](https://creativecommons.org/publicdomain/zero/1.0/)                                                                                              |
| <sub>[CaFE](https://www.gel.usherbrooke.ca/audio/cafe.htm)</sub>                                                                                                                                    | <sub>2018</sub> | <sub>6 different sentences by 12 speakers (6 fmelaes + 6 males).</sub>                                                                                | <sub>7 emotions: happy, sad, angry, fearful, surprise, disgust and neutral. Each emotion is acted in 2 different intensities.</sub>                                                                                                                                          | <sub>Audio</sub>              | <sub>~2 GB</sub>    | <sub>French (Canadian)</sub>  | <sub>--</sub>                                                                                                                                                                                                                                                           | Open access        | [CC BY-NC-SA 4.0]](https://creativecommons.org/licenses/by-nc-sa/4.0/)                                                                                     |
| <sub>[ANAD](https://www.kaggle.com/suso172/arabic-natural-audio-dataset)</sub>                                                                                                                      | <sub>2018</sub> | <sub>1384 recording by multiple speakers.</sub>                                                                                                       | <sub>3 emotions: angry, happy, surprised.</sub>                                                                                                                                                                                                                              | <sub>Audio</sub>              | <sub>~2 GB</sub>    | <sub>Arabic</sub>             | <sub>[Arabic Natural Audio Dataset](https://data.mendeley.com/datasets/xm232yxf7t/1) </sub>                                                                                                                                                                             | Open access        | [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)                                                                                      |
| <sub>[MSP-IMPROV](https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Improv.html)</sub>                                                                                                     | <sub>2017</sub> | <sub>20 sentences by 12 actors.</sub>                                                                                                                 | <sub>4 emotions: angry, sad, happy, neutral, other, without agreement</sub>                                                                                                                                                                                                  | <sub>Audio, Video</sub>       | <sub> -- </sub>     | <sub>English</sub>            | <sub>[MSP-IMPROV: An Acted Corpus of Dyadic Interactions to Study Emotion Perception](https://ecs.utdallas.edu/research/researchlabs/msp-lab/publications/Busso_2017.pdf)</sub>                                                                                         | Restricted access  | Available under an Academic License & Commercial License                                                                                                   |
| <sub>[CREMA-D](https://github.com/CheyneyComputerScience/CREMA-D)</sub>                                                                                                                             | <sub>2017</sub> | <sub>7442 clip of 12 sentences spoken by 91 actors (48 males and 43 females).</sub>                                                                   | <sub>6 emotions: angry, disgusted, fearful, happy, neutral, and sad</sub>                                                                                                                                                                                                    | <sub>Audio, Video</sub>       | <sub> -- </sub>     | <sub>English</sub>            | <sub>[CREMA-D: Crowd-sourced Emotional Multimodal Actors Dataset](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4313618/)</sub>                                                                                                                                          | Open access        | Available under the [Open Database License & Database Content License](https://github.com/CheyneyComputerScience/CREMA-D/blob/master/LICENSE.txt)          |
| <sub>[Example emotion videos used in investigation of emotion perception in schizophrenia.](https://espace.library.uq.edu.au/view/UQ:446541)</sub>                                                  | <sub>2017</sub> | <sub>6 videos:Two example videos from each emotion category (angry, happy and neutral) by one female speaker.</sub>                                   | <sub>3 emotions: angry, happy and neutral.</sub>                                                                                                                                                                                                                             | <sub>Audio, Video</sub>       | <sub>~63 MB</sub>   | <sub>English</sub>            | <sub>--</sub>                                                                                                                                                                                                                                                           | Open access        | Available under the [Permitted Non-commercial Re-use with Acknowledgement](https://guides.library.uq.edu.au/deposit_your_data/terms_and_conditions)        |
| <sub>[EMOVO](http://voice.fub.it/activities/corpora/emovo/index.html)</sub>                                                                                                                         | <sub>2014</sub> | <sub>6 actors  who  played  14  sentences.</sub>                                                                                                      | <sub>6 emotions: disgust, fear, anger, joy, surprise, sadness.</sub>                                                                                                                                                                                                         | <sub>Audio</sub>              | <sub> ~355 MB</sub> | <sub>Italian</sub>            | <sub>[EMOVO Corpus: an Italian Emotional Speech Database](https://core.ac.uk/download/pdf/53857389.pdf)</sub>                                                                                                                                                           | Open access        | None specified                                                                                                                                             |
| <sub>[RECOLA](https://diuf.unifr.ch/main/diva/recola/download.html)</sub>                                                                                                                           | <sub>2013</sub> | <sub>3.8 hours of recordings by 46 participants.</sub>                                                                                                | <sub>negative and positive sentiment (valence and arousal).</sub>                                                                                                                                                                                                            | <sub>Audio, Video</sub>       | <sub> -- </sub>     | <sub>--</sub>                 | <sub>[Introducing the RECOLA Multimodal Corpus of Remote Collaborative and Affective Interactions](https://drive.google.com/file/d/0B2V_I9XKBODhNENKUnZWNFdVXzQ/view)</sub>                                                                                             | Restricted access  | Available under an Academic License & Commercial License                                                                                                   |
| <sub>[GEMEP Corpus](https://www.unige.ch/cisa/gemep)</sub>                                                                                                                                          | <sub>2012</sub> | <sub>10 actors portraying 10 states.</sub>                                                                                                            | <sub>12 emotions: amusement, anxiety, cold anger (irritation), despair, hot anger (rage),  fear (panic), interest, joy (elation), pleasure(sensory), pride, relief, and sadness. Plus, 5 additional emotions: admiration, contempt, disgust, surprise, and tenderness.</sub> | <sub>Audio, Video</sub>       | <sub> -- </sub>     | <sub>French</sub>             | <sub>[Introducing the Geneva Multimodal Expression Corpus for Experimental Research on Emotion Perception](https://www.researchgate.net/publication/51796867_Introducing_the_Geneva_Multimodal_Expression_Corpus_for_Experimental_Research_on_Emotion_Perception)</sub> | Restricted access  | None specified                                                                                                                                             |
| <sub>[LEGO corpus](https://www.ultes.eu/ressources/lego-spoken-dialogue-corpus/)</sub>                                                                                                              | <sub>2012</sub> | <sub>347 dialogs with 9,083 system-user exchanges.</sub>                                                                                              | <sub>Emotions classified as garbage, non-angry, slightly angry and very angry.</sub>                                                                                                                                                                                         | <sub>Audio</sub>              | <sub>1.1 GB</sub>   | <sub>--</sub>                 | <sub>[A Parameterized and Annotated Spoken Dialog Corpus of the CMU Let’s Go Bus Information System](http://www.lrec-conf.org/proceedings/lrec2012/pdf/333_Paper.pdf)</sub>                                                                                             | Open access        | Lincese available with the data. Free of charges for research purposes only.                                                                               |
| <sub>[TESS](https://tspace.library.utoronto.ca/handle/1807/24487)</sub>                                                                                                                             | <sub>2010</sub> | <sub>2800 recording by 2 actresses.</sub>                                                                                                             | <sub>7 emotions: anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral.</sub>                                                                                                                                                                             | <sub>Audio</sub>              | <sub> -- </sub>     | <sub>English</sub>            | <sub>[BEHAVIOURAL FINDINGS FROM THE TORONTO EMOTIONAL SPEECH SET](https://www.semanticscholar.org/paper/BEHAVIOURAL-FINDINGS-FROM-THE-TORONTO-EMOTIONAL-SET-Dupuis-Pichora-Fuller/d7f746b3aee801a353b6929a65d9a34a68e71c6f/figure/2)</sub>                              | Open access        | [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)                                                                                      |
| <sub>[EEKK](https://metashare.ut.ee/repository/download/4d42d7a8463411e2a6e4005056b40024a19021a316b54b7fb707757d43d1a889/)</sub>                                                                    | <sub>2007</sub> | <sub>26 text passage read by 10 speakers.</sub>                                                                                                       | <sub>4 main emotions: joy, sadness, anger and neutral.</sub>                                                                                                                                                                                                                 | <sub>--</sub>                 | <sub>~352 MB</sub>  | <sub>Estonian</sub>           | <sub>[Estonian Emotional Speech Corpus](https://www.researchgate.net/publication/261724574_Estonian_Emotional_Speech_Corpus_Release_1)</sub>                                                                                                                            | Open access        | [CC-BY Licence](https://metashare.ut.ee/repository/download/4d42d7a8463411e2a6e4005056b40024a19021a316b54b7fb707757d43d1a889/)                             |
| <sub>[Keio-ESD](http://research.nii.ac.jp/src/en/Keio-ESD.html)</sub>                                                                                                                               | <sub>2006</sub> | <sub>A set of human speech with vocal emotion spoken by a Japanese male speaker.</sub>                                                                | <sub>47 emotions including angry, joyful, disgusting, downgrading, funny,  worried, gentle, relief, indignation, shameful, etc.</sub>                                                                                                                                        | <sub>Audio</sub>              | <sub> -- </sub>     | <sub>Japanese</sub>           | <sub>[EMOTIONAL SPEECH SYNTHESIS USING SUBSPACE CONSTRAINTS IN PROSODY](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.420.8899&rep=rep1&type=pdf)</sub>                                                                                                      | Restricted access  | Available for research purposes only                                                                                                                       |
| <sub>[EMO-DB](http://emodb.bilderbar.info/index-1280.html)</sub>                                                                                                                                    | <sub>2005</sub> | <sub>800 recording spoken by 10 actors (5 males and 5 females).</sub>                                                                                 | <sub>7 emotions: anger, neutral, fear, boredom, happiness, sadness, disgust.</sub>                                                                                                                                                                                           | <sub>Audio</sub>              | <sub> -- </sub>     | <sub>German</sub>             | <sub>[A Database of German Emotional Speech](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.8506&rep=rep1&type=pdf)</sub>                                                                                                                                 | Open access        | None specified                                                                                                                                             |
| <sub>[DES](http://kom.aau.dk/~tb/speech/Emotions/)</sub>                                                                                                                                            | <sub>2002</sub> | <sub>4 speakers (2 males and 2 females).</sub>                                                                                                        | <sub>5 emotions: neutral,  surprise,  happiness,  sadness  and  anger</sub>                                                                                                                                                                                                  | <sub> -- </sub>               | <sub> -- </sub>     | <sub>Danish</sub>             | <sub>[Documentation of the Danish Emotional Speech Database](http://kom.aau.dk/~tb/speech/Emotions/des.pdf)</sub>                                                                                                                                                       |


## References

- Swain, Monorama & Routray, Aurobinda & Kabisatpathy, Prithviraj, Databases, features and classifiers for speech emotion recognition: a review. International Journal of Speech Technology, [paper](https://www.researchgate.net/publication/322602563_Databases_features_and_classifiers_for_speech_emotion_recognition_a_review#pf19)
- Dimitrios Ververidis and Constantine Kotropoulos, A State of the Art Review on Emotional Speech Databases, Artificial Intelligence & Information Analysis Laboratory, Department of Informatics Aristotle, University of Thessaloniki, [paper](http://poseidon.csd.auth.gr/papers/PUBLISHED/CONFERENCE/pdf/Ververidis2003b.pdf)
- A. Pramod Reddy and V. Vijayarajan, Extraction of Emotions from Speech-A Survey, VIT University, International Journal of Applied Engineering Research, [paper](https://www.ripublication.com/ijaer17/ijaerv12n16_46.pdf)
- Emotional Speech Databases, [document](https://link.springer.com/content/pdf/bbm%3A978-90-481-3129-7%2F1.pdf)
- Expressive Synthetic Speech, [website](http://emosamples.syntheticspeech.de/)
- Untitled, Technical university Munich, [document](https://mediatum.ub.tum.de/doc/1137841/780196.pdf)
