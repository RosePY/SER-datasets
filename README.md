# Speech-Emotion-Recognition Dataset

| <sub>Dataset</sub>                                                                                                                                                                                  | <sub>Year</sub> | <sub>Content</sub>                                                                                               | <sub>Emotions</sub>                                                                                                                                                                                                                                                          | <sub>Format</sub>             | <sub>Size</sub>     | <sub>Language</sub> | <sub>Paper</sub>                                                                                                                                                                                                                                                        |
|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------|------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------|---------------------|---------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| <sub>[MELD](https://affective-meld.github.io/)</sub>                                                                                                                                                | <sub>2019</sub> | <sub>1400 dialogues and 14000 utterances from Friends TV series  by multiple speakers.</sub>                     | <sub>7 emotions: Anger, Disgust, Sadness, Joy, Neutral, Surprise and Fear.  MELD also has sentiment (positive, negative and neutral) annotation  for each utterance.</sub>                                                                                                   | <sub>Audio, Video, Text</sub> | <sub>~10.1 GB</sub> | <sub>English</sub>  | <sub>[MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations](https://arxiv.org/pdf/1810.02508.pdf)</sub>                                                                                                                                      |
| <sub>[MSP-IMPROV](https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Improv.html)</sub>                                                                                                     | <sub>2017</sub> | <sub>20 sentences by 12 actors.</sub>                                                                            | <sub>4 emotions: angry, sad, happy, neutral, other, without agreement</sub>                                                                                                                                                                                                  | <sub>Audio, Video</sub>       | <sub> -- </sub>     | <sub>English</sub>  | <sub>[MSP-IMPROV: An Acted Corpus of Dyadic Interactions to Study Emotion Perception](https://ecs.utdallas.edu/research/researchlabs/msp-lab/publications/Busso_2017.pdf)</sub>                                                                                         |
| <sub>[RAVDESS](https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio)</sub>                                                                                                             | <sub>2018</sub> | <sub>7356 recordings by 24 actors.</sub>                                                                         | <sub>7 emotions: calm, happy, sad, angry, fearful, surprise, and disgust</sub>                                                                                                                                                                                               | <sub>Audio, Video</sub>       | <sub>~24.8 GB</sub> | <sub>English</sub>  | <sub>[The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196391)</sub>                   |
| <sub>[CREMA-D](https://github.com/CheyneyComputerScience/CREMA-D)</sub>                                                                                                                             | <sub>2017</sub> | <sub>7442 clip of 12 sentences spoken by 91 actors (48 males and 43 females).</sub>                              | <sub>6 emotions: angry, disgusted, fearful, happy, neutral, and sad</sub>                                                                                                                                                                                                    | <sub>Audio, Video</sub>       | <sub> -- </sub>     | <sub>English</sub>  | <sub>[CREMA-D: Crowd-sourced Emotional Multimodal Actors Dataset](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4313618/)</sub>                                                                                                                                          |
| <sub>[JL corpus](https://www.kaggle.com/tli725/jl-corpus)</sub>                                                                                                                                     | <sub>2018</sub> | <sub>2400 recording of 240 sentences by 4 actors (2 males and 2 females).</sub>                                  | <sub>5 primary emotions: angry, sad, neutral, happy, excited. 5 secondary emotions: anxious, apologetic, pensive, worried, enthusiastic.</sub>                                                                                                                               | <sub>Audio</sub>              | <sub> -- </sub>     | <sub>English</sub>  | <sub>[An Open Source Emotional Speech Corpus for Human Robot Interaction Applications](https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1349.pdf)</sub>                                                                                                        |
| <sub>[EMO-DB](http://emodb.bilderbar.info/index-1280.html)</sub>                                                                                                                                    | <sub>2005</sub> | <sub>800 recording spoken by 10 actors (5 males and 5 females).</sub>                                            | <sub>7 emotions: anger, neutral, fear, boredom, happiness, sadness, disgust.</sub>                                                                                                                                                                                           | <sub>Audio</sub>              | <sub> -- </sub>     | <sub>German</sub>   | <sub>[A Database of German Emotional Speech](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.8506&rep=rep1&type=pdf)</sub>                                                                                                                                 |
| <sub>[ANAD](https://www.kaggle.com/suso172/arabic-natural-audio-dataset)</sub>                                                                                                                      | <sub>2018</sub> | <sub>1384 recording by multiple speakers.</sub>                                                                  | <sub>3 emotions: angry, happy, surprised.</sub>                                                                                                                                                                                                                              | <sub>Audio</sub>              | <sub>~2 GB</sub>    | <sub>Arabic</sub>   |                                                                                                                                                                                                                                                                         |
| <sub>[DES](http://kom.aau.dk/~tb/speech/Emotions/)</sub>                                                                                                                                            | <sub>2002</sub> | <sub> 4 speakers (2 males and 2 females).</sub>                                                                  | <sub>5 emotions: neutral,  surprise,  happiness,  sadness  and  anger</sub>                                                                                                                                                                                                  | <sub> -- </sub>               | <sub> -- </sub>     | <sub>Danish</sub>   | <sub>[Documentation of the Danish Emotional Speech Database](http://kom.aau.dk/~tb/speech/Emotions/des.pdf)</sub>                                                                                                                                                       |
| <sub>[TESS](https://tspace.library.utoronto.ca/handle/1807/24487)</sub>                                                                                                                             | <sub>2010</sub> | <sub>2800 recording by 2 actresses.</sub>                                                                        | <sub>7 emotions: anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral.</sub>                                                                                                                                                                             | <sub>Audio</sub>              | <sub> -- </sub>     | <sub>English</sub>  | <sub>[BEHAVIOURAL FINDINGS FROM THE TORONTO EMOTIONAL SPEECH SET](https://www.semanticscholar.org/paper/BEHAVIOURAL-FINDINGS-FROM-THE-TORONTO-EMOTIONAL-SET-Dupuis-Pichora-Fuller/d7f746b3aee801a353b6929a65d9a34a68e71c6f/figure/2)</sub>                              |
| <sub>[RECOLA](https://diuf.unifr.ch/main/diva/recola/download.html)</sub>                                                                                                                           | <sub>2013</sub> | <sub>3.8 hours of recordings by 46 participants.</sub>                                                           | <sub>negative and positive sentiment (valence and arousal).</sub>                                                                                                                                                                                                            | <sub>Audio, Video</sub>       | <sub> -- </sub>     | <sub> -- </sub>     | <sub>[Introducing the RECOLA Multimodal Corpus of Remote Collaborative and Affective Interactions](https://drive.google.com/file/d/0B2V_I9XKBODhNENKUnZWNFdVXzQ/view)</sub>                                                                                             |
| <sub>[EMOVO](http://voice.fub.it/activities/corpora/emovo/index.html)</sub>                                                                                                                         | <sub>2014</sub> | <sub>6  actors  who  played  14  sentences.</sub>                                                                | <sub>6 emotions: disgust, fear, anger, joy, surprise, sadness.</sub>                                                                                                                                                                                                         | <sub>Audio</sub>              | <sub> -- </sub>     | <sub>Italian</sub>  | <sub>[EMOVO Corpus: an Italian Emotional Speech Database](https://core.ac.uk/download/pdf/53857389.pdf)</sub>                                                                                                                                                           |
| <sub>[Keio-ESD](http://research.nii.ac.jp/src/en/Keio-ESD.html)</sub>                                                                                                                               | <sub>2006</sub> | <sub> A set of human speech with vocal emotion spoken by a Japanese male speaker.</sub>                          | <sub> 47 emotions including angry, joyful, disgusting, downgrading, funny,  worried, gentle, relief, indignation, shameful, etc.</sub>                                                                                                                                       | <sub>Audio</sub>              | <sub> -- </sub>     | <sub>Japanese</sub> | <sub>[EMOTIONAL SPEECH SYNTHESIS USING SUBSPACE CONSTRAINTS IN PROSODY](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.420.8899&rep=rep1&type=pdf)</sub>                                                                                                      |
| <sub>[GEMEP Corpus](https://www.unige.ch/cisa/gemep)</sub>                                                                                                                                          | <sub>2012</sub> | <sub>10 actors portraying 10 states.</sub>                                                                       | <sub>12 emotions: amusement, anxiety, cold anger (irritation), despair, hot anger (rage),  fear (panic), interest, joy (elation), pleasure(sensory), pride, relief, and sadness. Plus, 5 additional emotions: admiration, contempt, disgust, surprise, and tenderness.</sub> | <sub>Audio, Video</sub>       | <sub> -- </sub>     | <sub>French</sub>   | <sub>[Introducing the Geneva Multimodal Expression Corpus for Experimental Research on Emotion Perception](https://www.researchgate.net/publication/51796867_Introducing_the_Geneva_Multimodal_Expression_Corpus_for_Experimental_Research_on_Emotion_Perception)</sub> |
| <sub>[Emov-DB](https://mega.nz/#F!KBp32apT!gLIgyWf9iQ-yqnWFUFuUHg!mYwUnI4K)</sub>                                                                                                                   | <sub>2018</sub> | <sub>Recordings for 4 speakers- 2 males and 2 females.</sub>                                                     | <sub>The emotional styles are neutral, sleepiness, anger, disgust and amused.</sub>                                                                                                                                                                                          | <sub>Audio</sub>              | <sub>5.88 GB</sub>  | <sub>English</sub>  | <sub> [](https://arxiv.org/pdf/1806.09514.pdf)</sub>                                                                                                                                                                                                                    |
| <sub>[EEKK](https://metashare.ut.ee/repository/download/4d42d7a8463411e2a6e4005056b40024a19021a316b54b7fb707757d43d1a889/)</sub>                                                                    | <sub>2007</sub> | <sub>26 text passage read by 10 speakers.</sub>                                                                  | <sub>4 main emotions: joy, sadness, anger and neutral.</sub>                                                                                                                                                                                                                 | <sub>--</sub>                 | <sub>--</sub>       | <sub>Estonian</sub> | <sub>[Estonian Emotional Speech Corpus](https://www.researchgate.net/publication/261724574_Estonian_Emotional_Speech_Corpus_Release_1)</sub>                                                                                                                            |
| <sub>[Emotional speech synthesis database](http://metashare.elda.org/repository/browse/emotional-speech-synthesis-database/12826ca2de6711e2b1e400259011f6eaae753c75913e40c7a9a5fed0bbf11368/)</sub> | <sub>--</sub>   | <sub>Recordings of one male and one female Spanish professional speakers recorded in a noise-reduced room.</sub> | <sub>--</sub>                                                                                                                                                                                                                                                                | <sub>--</sub>                 | <sub>--</sub>       | <sub>Spanish</sub>  | <sub>--</sub>                                                                                                                                                                                                                                                           |
| <sub>[LEGO corpus](https://www.ultes.eu/ressources/lego-spoken-dialogue-corpus/)</sub>                                                                                                              | <sub>2012</sub> | <sub>347 dialogs with 9,083 system-user exchanges.</sub>                                                         | <sub>Emotions classified as garbage, non-angry, slightly angry and very angry.</sub>                                                                                                                                                                                         | <sub>Audio</sub>              | <sub>1.1 GB</sub>   | <sub>--</sub>       | <sub>[A Parameterized and Annotated Spoken Dialog Corpus of the CMU Let’s Go Bus Information System](http://www.lrec-conf.org/proceedings/lrec2012/pdf/333_Paper.pdf)</sub>                                                                                             |

## References

- [Databases, features and classifiers for speech emotion recognition: a review](https://www.researchgate.net/publication/322602563_Databases_features_and_classifiers_for_speech_emotion_recognition_a_review#pf19)
- [A State of the Art Review on Emotional Speech Databases](http://poseidon.csd.auth.gr/papers/PUBLISHED/CONFERENCE/pdf/Ververidis2003b.pdf)
- [Extraction of Emotions from Speech-A Survey](https://www.ripublication.com/ijaer17/ijaerv12n16_46.pdf)
- [Emotional Speech Databases](https://link.springer.com/content/pdf/bbm%3A978-90-481-3129-7%2F1.pdf)
- [TUM document](https://mediatum.ub.tum.de/doc/1137841/780196.pdf)
- [Expressive Synthetic Speech](http://emosamples.syntheticspeech.de/)
